seed=22
dataset='hh_rlhf'
basemodel='llama3-8b'
######sft############
# train
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project sft --global_batch_size 24 --learning_rate 5e-6 --max_grad_norm 10.0 --sample_ontest --n_epoch 2 

# eval
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name llama3-8b  --dataset hh_rlhf  --global_batch_size 64  --eval_only --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --sample_ontest 

#######reward########
# #train
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project reward --global_batch_size 16 --learning_rate 5e-6 --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf --n_epoch 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project reward --global_batch_size 16 --learning_rate 5e-6 --reward_reg   --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf_reg --n_epoch 1 
# For WARM
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project reward --global_batch_size 16 --learning_rate 7e-6 --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf_M1 --seed 23 --n_examples 8624
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project reward --global_batch_size 16 --learning_rate 6e-6 --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf_M2 --seed 24 --n_examples 17216
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project reward --global_batch_size 16 --learning_rate 5e-6 --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf_M3 --seed 25 --n_examples 25824
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project reward --global_batch_size 16 --learning_rate 4e-6 --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf_M4 --seed 26 --n_examples 34400
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project reward --global_batch_size 16 --learning_rate 3e-6 --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf_M5 --seed 27 --n_examples 42400
# rlaunch --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- python3 model_merge.py --base_model_name llama3-8b --dataset_name hh_rlhf

# For ODIN
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward_odin --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project reward --global_batch_size 16 --learning_rate 5e-6 --reward_odin --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf_odin --n_epoch 1 


#############generate references and calculate reward################
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name gen_refs --model_name llama3-8b --dataset hh_rlhf --global_batch_size 16 --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf --reward_tag latest_hf --n_epoch 1 
# python utils.py


#######ppo########
#Lab1
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --exp_name ppo_llama3-8b_hh_rlhf_vanilla   --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf_WARM    --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf_WARM    --critic_tag latest_hf  --exp_name ppo_llama3-8b_hh_rlhf_WARM  --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf_odin    --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf_odin    --critic_tag latest_hf  --reward_odin --exp_name ppo_llama3-8b_hh_rlhf_ODIN   --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf_reg --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf_reg     --critic_tag latest_hf  --exp_name ppo_llama3-8b_hh_rlhf_reg  --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_llama3-8b_hh_rlhf_meanstd  --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_llama3-8b_hh_rlhf_clip    --n_epochs 1
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_llama3-8b_hh_rlhf_minmax    --n_epochs 1
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_lsc  --reward_relative --exp_name ppo_llama3-8b_hh_rlhf_lsc   --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_sigmoid  --reward_relative --exp_name ppo_llama3-8b_hh_rlhf_PAR   --n_epochs 1 
# Evaluate on benchmark