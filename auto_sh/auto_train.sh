rlaunch --cpu=100 --memory=800000 --gpu=8 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  -- bash
rlaunch --cpu=100 --memory=500000 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  -- bash
#random seed=22
######sft############
# train
# Gemma2-2B
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project sft --global_batch_size 48 --learning_rate 5e-6 --max_grad_norm 10.0 --sample_ontest --n_epoch 2 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project sft --global_batch_size 48 --learning_rate 5e-6 --max_grad_norm 10.0 --sample_ontest --n_epoch 2 
# Llama3-8B
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project sft --global_batch_size 24 --learning_rate 5e-6 --max_grad_norm 10.0 --sample_ontest --n_epoch 2 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project sft --global_batch_size 24 --learning_rate 5e-6 --max_grad_norm 10.0 --sample_ontest --n_epoch 2 

# eval
# Gemma2-2B
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name gemma2-2b  --dataset ultrafb_bin  --global_batch_size 128  --eval_only --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --sample_ontest 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name gemma2-2b  --dataset hh_rlhf  --global_batch_size 128  --eval_only --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --sample_ontest 
# Llama3-8B
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name llama3-8b  --dataset ultrafb_bin  --global_batch_size 64  --eval_only --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --sample_ontest 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name sft --model_name llama3-8b  --dataset hh_rlhf  --global_batch_size 64  --eval_only --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --sample_ontest 

#######reward########
# #train, Gemma2-2B
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --max_grad_norm 5.0 --exp_name reward_gemma2-2b_ultrafb_bin --n_epoch 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --reward_reg   --max_grad_norm 5.0 --exp_name reward_gemma2-2b_ultrafb_bin_reg --n_epoch 1 
# For WARM
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 7e-6 --max_grad_norm 5.0 --exp_name reward_gemma2-2b_ultrafb_bin_M1 --seed 23 --n_examples 9700
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 6e-6 --max_grad_norm 5.0 --exp_name reward_gemma2-2b_ultrafb_bin_M2 --seed 24 --n_examples 14300
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --max_grad_norm 5.0 --exp_name reward_gemma2-2b_ultrafb_bin_M3 --seed 25 --n_examples 19200
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 4e-6 --max_grad_norm 5.0 --exp_name reward_gemma2-2b_ultrafb_bin_M4 --seed 26 --n_examples 24000
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 3e-6 --max_grad_norm 5.0 --exp_name reward_gemma2-2b_ultrafb_bin_M5 --seed 27 --n_examples 28800
# For ODIN
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward_odin --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --reward_odin --max_grad_norm 5.0 --exp_name reward_gemma2-2b_ultrafb_bin_odin --n_epoch 1 


# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset hh_rlhf     --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --max_grad_norm 5.0 --exp_name reward_gemma2-2b_hh_rlhf --n_epoch 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name gemma2-2b  --dataset hh_rlhf     --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --reward_reg  --max_grad_norm 5.0 --exp_name reward_gemma2-2b_hh_rlhf_reg --n_epoch 1 
# #train, Llama3-8B
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --max_grad_norm 5.0 --exp_name reward_llama3-8b_ultrafb_bin --n_epoch 1 
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset ultrafb_bin --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --reward_reg   --max_grad_norm 5.0 --exp_name reward_llama3-8b_ultrafb_bin_reg --n_epoch 1 
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf     --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf --n_epoch 1 
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name reward --model_name llama3-8b  --dataset hh_rlhf     --wandb_enabled --wandb_project reward --global_batch_size 24 --learning_rate 5e-6 --reward_reg   --max_grad_norm 5.0 --exp_name reward_llama3-8b_hh_rlhf_reg --n_epoch 1 


#############generate references and calculate reward################
#Gemma2-2B
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name gen_refs --model_name gemma2-2b --dataset ultrafb_bin --global_batch_size 32 --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin --reward_tag latest_hf --n_epoch 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name gen_refs --model_name gemma2-2b --dataset hh_rlhf --global_batch_size 32 --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf --reward_tag latest_hf --n_epoch 1 
#Llama3-8B
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name gen_refs --model_name llama3-8b --dataset ultrafb_bin --global_batch_size 32 --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin --reward_tag latest_hf --n_epoch 1 
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name gen_refs --model_name llama3-8b --dataset hh_rlhf --global_batch_size 32 --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf --reward_tag latest_hf --n_epoch 1 
python utils.py


# main plot: 
#1. After training one epoch, PPO sigmoid is better than sft while PPO vanilla is worse than sft?
#2. Introduce gpt4o winrate curve and explain the reward hacking phenomenon.

# branch plot:
#1. PPO sigmoid can maintain peak winrate during a long period while PPO vanilla can only reach peak winrate in a flash
#2. PPO sigmoid peak winrate is no worse than PPO vanilla peak winrate

#######ppo########
#ultrafb, Gemma2-2B
#PPO sigmoid peak winrate is no worse than PPO vanilla peak winrate,  After training one epoch, PPO sigmoid is better than sft while PPO vanilla is worse than sft? Introduce gpt4o winrate curve and explain the reward hacking phenomenon.
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --exp_name ppo_gemma2-2b_ultrafb_bin_vanilla --intermediate_checkpoints --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin_reg --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin_reg     --critic_tag latest_hf  --exp_name ppo_gemma2-2b_ultrafb_bin_reg --intermediate_checkpoints --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_gemma2-2b_ultrafb_bin_meanstd  --intermediate_checkpoints --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_gemma2-2b_ultrafb_bin_clip  --intermediate_checkpoints --n_epochs 1
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_gemma2-2b_ultrafb_bin_minmax  --intermediate_checkpoints --n_epochs 1
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_lsc  --exp_name ppo_gemma2-2b_ultrafb_bin_lsc  --intermediate_checkpoints --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_sigmoid  --exp_name ppo_gemma2-2b_ultrafb_bin_sigmoid  --intermediate_checkpoints --n_epochs 1 
# rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_par  --exp_name ppo_gemma2-2b_ultrafb_bin_par  --intermediate_checkpoints --n_epochs 1 

#PPO sigmoid can maintain peak winrate during a long period while PPO vanilla can only reach peak winrate in a flash, Introduce gpt4o winrate curve and explain the reward hacking phenomenon.
# wait...
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --exp_name ppo_gemma2-2b_ultrafb_bin_vanilla_ep3 --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin_reg --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin_reg     --critic_tag latest_hf  --exp_name ppo_gemma2-2b_ultrafb_bin_reg_ep3 --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_gemma2-2b_ultrafb_bin_meanstd_ep3  --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_gemma2-2b_ultrafb_bin_clip_ep3    --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_gemma2-2b_ultrafb_bin_minmax_ep3    --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_lsc  --exp_name ppo_gemma2-2b_ultrafb_bin_lsc_ep3      --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_sigmoid  --exp_name ppo_gemma2-2b_ultrafb_bin_sigmoid_ep3  --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_ultrafb_bin         --critic_tag latest_hf  --reward_par  --exp_name ppo_gemma2-2b_ultrafb_bin_par_ep3  --n_epochs 3 


#hh-rlhf, Gemma2-2B
#PPO sigmoid peak winrate is no worse than PPO vanilla peak winrate,  After training one epoch, PPO sigmoid is better than sft while PPO vanilla is worse than sft? Introduce gpt4o winrate curve and explain the reward hacking phenomenon.
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --exp_name ppo_gemma2-2b_hh_rlhf_vanilla --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf_reg --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf_reg     --critic_tag latest_hf  --exp_name ppo_gemma2-2b_hh_rlhf_reg --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_gemma2-2b_hh_rlhf_meanstd  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_gemma2-2b_hh_rlhf_clip  --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_gemma2-2b_hh_rlhf_minmax  --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_lsc  --exp_name ppo_gemma2-2b_hh_rlhf_lsc  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_sigmoid  --exp_name ppo_gemma2-2b_hh_rlhf_sigmoid  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_par  --exp_name ppo_gemma2-2b_hh_rlhf_par  --intermediate_checkpoints --n_epochs 1 

#PPO sigmoid can maintain peak winrate during a long period while PPO vanilla can only reach peak winrate in a flash, Introduce gpt4o winrate curve and explain the reward hacking phenomenon.
# wait...
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --exp_name ppo_gemma2-2b_hh_rlhf_vanilla_ep3 --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf_reg --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf_reg     --critic_tag latest_hf  --exp_name ppo_gemma2-2b_hh_rlhf_reg_ep3 --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_gemma2-2b_hh_rlhf_meanstd_ep3  --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_gemma2-2b_hh_rlhf_clip_ep3    --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_gemma2-2b_hh_rlhf_minmax_ep3    --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_lsc  --exp_name ppo_gemma2-2b_hh_rlhf_lsc_ep3      --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_sigmoid  --exp_name ppo_gemma2-2b_hh_rlhf_sigmoid_ep3  --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name gemma2-2b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 40 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_gemma2-2b_hh_rlhf         --critic_tag latest_hf  --reward_par  --exp_name ppo_gemma2-2b_hh_rlhf_par_ep3  --n_epochs 3 


#ultrafb, Llama3-8B
#PPO sigmoid peak winrate is no worse than PPO vanilla peak winrate,  After training one epoch, PPO sigmoid is better than sft while PPO vanilla is worse than sft? Introduce gpt4o winrate curve and explain the reward hacking phenomenon.
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --exp_name ppo_llama3-8b_ultrafb_bin_vanilla --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin_reg --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin_reg     --critic_tag latest_hf  --exp_name ppo_llama3-8b_ultrafb_bin_reg --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_llama3-8b_ultrafb_bin_meanstd  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_llama3-8b_ultrafb_bin_clip  --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_llama3-8b_ultrafb_bin_minmax  --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_lsc  --exp_name ppo_llama3-8b_ultrafb_bin_lsc  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_sigmoid  --exp_name ppo_llama3-8b_ultrafb_bin_sigmoid  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_par  --exp_name ppo_llama3-8b_ultrafb_bin_par  --intermediate_checkpoints --n_epochs 1 

#PPO sigmoid can maintain peak winrate during a long period while PPO vanilla can only reach peak winrate in a flash, Introduce gpt4o winrate curve and explain the reward hacking phenomenon.
# wait...
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --exp_name ppo_llama3-8b_ultrafb_bin_vanilla_ep3 --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin_reg --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin_reg     --critic_tag latest_hf  --exp_name ppo_llama3-8b_ultrafb_bin_reg_ep3 --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_llama3-8b_ultrafb_bin_meanstd_ep3  --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_llama3-8b_ultrafb_bin_clip_ep3    --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_llama3-8b_ultrafb_bin_minmax_ep3    --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_lsc  --exp_name ppo_llama3-8b_ultrafb_bin_lsc_ep3      --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_sigmoid  --exp_name ppo_llama3-8b_ultrafb_bin_sigmoid_ep3  --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset ultrafb_bin --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_ultrafb_bin         --critic_tag latest_hf  --reward_par  --exp_name ppo_llama3-8b_ultrafb_bin_par_ep3  --n_epochs 3 


#hh-rlhf, Llama3-8B
#PPO sigmoid peak winrate is no worse than PPO vanilla peak winrate,  After training one epoch, PPO sigmoid is better than sft while PPO vanilla is worse than sft? Introduce gpt4o winrate curve and explain the reward hacking phenomenon.
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --exp_name ppo_llama3-8b_hh_rlhf_vanilla --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf_reg --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf_reg     --critic_tag latest_hf  --exp_name ppo_llama3-8b_hh_rlhf_reg --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_llama3-8b_hh_rlhf_meanstd  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_llama3-8b_hh_rlhf_clip  --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_llama3-8b_hh_rlhf_minmax  --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_lsc  --exp_name ppo_llama3-8b_hh_rlhf_lsc  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_sigmoid  --exp_name ppo_llama3-8b_hh_rlhf_sigmoid  --intermediate_checkpoints --n_epochs 1 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_par  --exp_name ppo_llama3-8b_hh_rlhf_par  --intermediate_checkpoints --n_epochs 1 

#PPO sigmoid can maintain peak winrate during a long period while PPO vanilla can only reach peak winrate in a flash, Introduce gpt4o winrate curve and explain the reward hacking phenomenon.
# wait...
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --exp_name ppo_llama3-8b_hh_rlhf_vanilla_ep3 --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf_reg --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf_reg     --critic_tag latest_hf  --exp_name ppo_llama3-8b_hh_rlhf_reg_ep3 --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_meanstd  --exp_name ppo_llama3-8b_hh_rlhf_meanstd_ep3  --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_clipping  --exp_name ppo_llama3-8b_hh_rlhf_clip_ep3    --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_minmax  --exp_name ppo_llama3-8b_hh_rlhf_minmax_ep3    --n_epochs 3
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_lsc  --exp_name ppo_llama3-8b_hh_rlhf_lsc_ep3      --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_sigmoid  --exp_name ppo_llama3-8b_hh_rlhf_sigmoid_ep3  --n_epochs 3 
rlaunch --gpu=8 --cpu=100 --replica=1 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name ppo --model_name llama3-8b --dataset hh_rlhf --wandb_enabled --wandb_project ppo --global_batch_size 16 --learning_rate 3e-7  --critic_lr 5e-6 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf     --reward_tag latest_hf  --critic_path /data/models/reward_llama3-8b_hh_rlhf         --critic_tag latest_hf  --reward_par  --exp_name ppo_llama3-8b_hh_rlhf_par_ep3  --n_epochs 3 




####dpo###
##offline
#Gemma2-2B
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project xpo --global_batch_size 32 --learning_rate 3e-7 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin  --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin --reward_tag latest_hf --exp_name dpo_gemma2-2b_ultrafb_bin_offline --n_epochs 1  --sample_ontest
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name gemma2-2b  --dataset hh_rlhf --wandb_enabled --wandb_project xpo --global_batch_size 32 --learning_rate 3e-7 --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf  --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf --reward_tag latest_hf --exp_name dpo_gemma2-2b_hh_rlhf_offline --n_epochs 1  --sample_ontest
#Llama3-8B
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name llama3-8b  --dataset ultrafb_bin --wandb_enabled --wandb_project xpo --global_batch_size 16 --learning_rate 3e-7 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin  --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin --reward_tag latest_hf --exp_name dpo_llama3-8b_ultrafb_bin_offline --n_epochs 1  --sample_ontest
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project xpo --global_batch_size 16 --learning_rate 3e-7 --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf  --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf --reward_tag latest_hf --exp_name dpo_llama3-8b_hh_rlhf_offline --n_epochs 1  --sample_ontest

##online
#Gemma2-2B
#ultrafb
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project xpo --global_batch_size 32 --learning_rate 3e-7  --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin  --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin --reward_tag latest_hf  --online --exp_name dpo_gemma2-2b_ultrafb_bin_online_vanilla  --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name gemma2-2b  --dataset ultrafb_bin --wandb_enabled --wandb_project xpo --global_batch_size 32 --learning_rate 3e-7  --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_ultrafb_bin  --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_ultrafb_bin --reward_tag latest_hf  --online --reward_discrete --exp_name dpo_gemma2-2b_ultrafb_bin_online_discrete --intermediate_checkpoints --n_epochs 1
#hh_rlhf
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name gemma2-2b  --dataset hh_rlhf --wandb_enabled --wandb_project xpo --global_batch_size 32 --learning_rate 3e-7  --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf  --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf --reward_tag latest_hf  --online --exp_name dpo_gemma2-2b_hh_rlhf_online_vanilla --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name gemma2-2b  --dataset hh_rlhf --wandb_enabled --wandb_project xpo --global_batch_size 32 --learning_rate 3e-7  --max_grad_norm 5.0  --policy_path /data/models/sft_gemma2-2b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_gemma2-2b_hh_rlhf  --reference_tag latest_hf --reward_path /data/models/reward_gemma2-2b_hh_rlhf --reward_tag latest_hf  --online --reward_discrete --exp_name dpo_gemma2-2b_hh_rlhf_online_discrete --intermediate_checkpoints --n_epochs 1

#Llama3-8B
#ultrafb
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name llama3-8b  --dataset ultrafb_bin --wandb_enabled --wandb_project xpo --global_batch_size 16 --learning_rate 3e-7  --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin  --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin --reward_tag latest_hf  --online --exp_name dpo_llama3-8b_ultrafb_bin_online_vanilla --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name llama3-8b  --dataset ultrafb_bin --wandb_enabled --wandb_project xpo --global_batch_size 16 --learning_rate 3e-7  --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_ultrafb_bin --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_ultrafb_bin  --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_ultrafb_bin --reward_tag latest_hf  --online --reward_discrete --exp_name dpo_llama3-8b_ultrafb_bin_online_discrete --intermediate_checkpoints --n_epochs 1
#hh_rlhf
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project xpo --global_batch_size 16 --learning_rate 3e-7  --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf  --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf --reward_tag latest_hf  --online --exp_name dpo_llama3-8b_hh_rlhf_online_vanilla --intermediate_checkpoints --n_epochs 1
rlaunch --gpu=8 --cpu=100 --replica=2 --memory=800000 --set-env NCCL_PXN_DISABLE=1 --charged-group=stepchat --private-machine=group --positive-tags feature/gpfs=yes  --custom-resources mellanox.com/mlnx_rdma=1 --custom-resources rdma/mlnx_shared=8 -- /mnt/shared-storage/tenant/jobutils/scripts/smartrun train.py --loss_name dpo --model_name llama3-8b  --dataset hh_rlhf --wandb_enabled --wandb_project xpo --global_batch_size 16 --learning_rate 3e-7  --max_grad_norm 5.0  --policy_path /data/models/sft_llama3-8b_hh_rlhf --policy_tag latest_hf --reference_path /data/models/sft_llama3-8b_hh_rlhf  --reference_tag latest_hf --reward_path /data/models/reward_llama3-8b_hh_rlhf --reward_tag latest_hf  --online --reward_discrete --exp_name dpo_llama3-8b_hh_rlhf_online_discrete --intermediate_checkpoints --n_epochs 1
